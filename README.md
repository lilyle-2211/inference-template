# Inference Template

This repository provides a production-ready template for deploying machine learning inference services.

**Tech stack:**
- FastAPI for serving models
- Docker for containerization
- Helm for Kubernetes deployments
- Terraform for infrastructure as code
- GitHub Actions for CI/CD
